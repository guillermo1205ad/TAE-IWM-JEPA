{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 216000, Validation size: 24000\n",
      "Entrenando TAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 422/422 [03:02<00:00,  2.31it/s, Loss=0.826]\n",
      "Epoch 2/10: 100%|██████████| 422/422 [03:07<00:00,  2.25it/s, Loss=0.128] \n",
      "Epoch 3/10: 100%|██████████| 422/422 [03:08<00:00,  2.24it/s, Loss=0.123] \n",
      "Epoch 4/10: 100%|██████████| 422/422 [03:08<00:00,  2.23it/s, Loss=0.118] \n",
      "Epoch 5/10: 100%|██████████| 422/422 [03:08<00:00,  2.24it/s, Loss=0.082] \n",
      "Epoch 6/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=0.0731]\n",
      "Epoch 7/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=0.0705]\n",
      "Epoch 8/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=0.0677]\n",
      "Epoch 9/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=0.0562]\n",
      "Epoch 10/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=0.0473]\n",
      "Saving tae_representations.pkl: 100%|██████████| 235/235 [00:06<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations saved to tae_representations.pkl\n",
      "Entrenando TVAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.26] \n",
      "Epoch 2/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.24] \n",
      "Epoch 3/10: 100%|██████████| 422/422 [03:08<00:00,  2.24it/s, Loss=1.24] \n",
      "Epoch 4/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.24] \n",
      "Epoch 5/10: 100%|██████████| 422/422 [03:08<00:00,  2.23it/s, Loss=1.24] \n",
      "Epoch 6/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.24] \n",
      "Epoch 7/10: 100%|██████████| 422/422 [03:08<00:00,  2.23it/s, Loss=1.23] \n",
      "Epoch 8/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.24] \n",
      "Epoch 9/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.23] \n",
      "Epoch 10/10: 100%|██████████| 422/422 [03:09<00:00,  2.23it/s, Loss=1.23] \n",
      "Saving tvae_representations.pkl: 100%|██████████| 235/235 [00:06<00:00, 34.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations saved to tvae_representations.pkl\n",
      "Evaluando MIG y DCI para TAE y TVAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gperaltag/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAE MIG: 0.026787081159060967, TAE DCI: 0.07815311970843693\n",
      "TVAE MIG: 3.4842608072310507e-06, TVAE DCI: 0.08165103878308098\n",
      "Best model for IWM JEPA: TAE\n",
      "Entrenando IWM JEPA Predictor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 1/50: 100%|██████████| 844/844 [00:22<00:00, 37.15it/s, Loss=9.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 1, Loss: 9.549289584724823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 2/50: 100%|██████████| 844/844 [00:22<00:00, 37.39it/s, Loss=4.77] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 2, Loss: 4.767750910673096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 3/50: 100%|██████████| 844/844 [00:22<00:00, 37.09it/s, Loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 3, Loss: 3.579071264413861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 4/50: 100%|██████████| 844/844 [00:22<00:00, 37.15it/s, Loss=2.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 4, Loss: 2.9808663398168664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 5/50: 100%|██████████| 844/844 [00:22<00:00, 37.19it/s, Loss=2.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 5, Loss: 2.6641454727728786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 6/50: 100%|██████████| 844/844 [00:22<00:00, 37.33it/s, Loss=2.47] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 6, Loss: 2.4723788799267807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 7/50: 100%|██████████| 844/844 [00:22<00:00, 37.42it/s, Loss=2.35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 7, Loss: 2.3479428763073202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 8/50: 100%|██████████| 844/844 [00:22<00:00, 37.16it/s, Loss=2.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 8, Loss: 2.2501683108049546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 9/50: 100%|██████████| 844/844 [00:22<00:00, 36.98it/s, Loss=2.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 9, Loss: 2.1795124551413747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 10/50: 100%|██████████| 844/844 [00:22<00:00, 37.13it/s, Loss=2.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 10, Loss: 2.1123713835438283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 11/50: 100%|██████████| 844/844 [00:22<00:00, 37.19it/s, Loss=2.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 11, Loss: 2.0697249144456964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 12/50: 100%|██████████| 844/844 [00:22<00:00, 37.17it/s, Loss=2.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 12, Loss: 2.0170686429993236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 13/50: 100%|██████████| 844/844 [00:22<00:00, 37.07it/s, Loss=1.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 13, Loss: 1.975217038844999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 14/50: 100%|██████████| 844/844 [00:22<00:00, 37.27it/s, Loss=1.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 14, Loss: 1.9284846067993562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 15/50: 100%|██████████| 844/844 [00:22<00:00, 37.12it/s, Loss=1.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 15, Loss: 1.8978852735593985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 16/50: 100%|██████████| 844/844 [00:22<00:00, 37.20it/s, Loss=1.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 16, Loss: 1.8707664638616464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 17/50: 100%|██████████| 844/844 [00:22<00:00, 37.25it/s, Loss=1.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 17, Loss: 1.842900204997492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 18/50: 100%|██████████| 844/844 [00:22<00:00, 37.12it/s, Loss=1.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 18, Loss: 1.818584969540908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 19/50: 100%|██████████| 844/844 [00:22<00:00, 37.30it/s, Loss=1.79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 19, Loss: 1.790524871993404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 20/50: 100%|██████████| 844/844 [00:22<00:00, 37.34it/s, Loss=1.77] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 20, Loss: 1.7660667208416203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 21/50: 100%|██████████| 844/844 [00:22<00:00, 37.21it/s, Loss=1.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 21, Loss: 1.7415844912495093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 22/50: 100%|██████████| 844/844 [00:22<00:00, 37.25it/s, Loss=1.72] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 22, Loss: 1.7237950276707021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 23/50: 100%|██████████| 844/844 [00:22<00:00, 37.19it/s, Loss=1.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 23, Loss: 1.6974902609230782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 24/50: 100%|██████████| 844/844 [00:22<00:00, 37.20it/s, Loss=1.68] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 24, Loss: 1.6786941870411425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 25/50: 100%|██████████| 844/844 [00:22<00:00, 37.25it/s, Loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 25, Loss: 1.655157514940506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 26/50: 100%|██████████| 844/844 [00:22<00:00, 37.20it/s, Loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 26, Loss: 1.644217922930469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 27/50: 100%|██████████| 844/844 [00:22<00:00, 37.32it/s, Loss=1.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 27, Loss: 1.6280499532889416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 28/50: 100%|██████████| 844/844 [00:22<00:00, 37.26it/s, Loss=1.61] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 28, Loss: 1.6149404759373145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 29/50: 100%|██████████| 844/844 [00:22<00:00, 37.23it/s, Loss=1.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 29, Loss: 1.5959248984876968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 30/50: 100%|██████████| 844/844 [00:22<00:00, 37.00it/s, Loss=1.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 30, Loss: 1.5858129771399836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 31/50: 100%|██████████| 844/844 [00:22<00:00, 37.09it/s, Loss=1.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 31, Loss: 1.5708314639414656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 32/50: 100%|██████████| 844/844 [00:22<00:00, 37.34it/s, Loss=1.55] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 32, Loss: 1.5545150978022841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 33/50: 100%|██████████| 844/844 [00:22<00:00, 37.32it/s, Loss=1.54] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 33, Loss: 1.5405287975666082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 34/50: 100%|██████████| 844/844 [00:22<00:00, 37.12it/s, Loss=1.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 34, Loss: 1.5331027592527924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 35/50: 100%|██████████| 844/844 [00:22<00:00, 37.08it/s, Loss=1.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 35, Loss: 1.5180081760431352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 36/50: 100%|██████████| 844/844 [00:22<00:00, 37.32it/s, Loss=1.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 36, Loss: 1.5149562953490217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 37/50: 100%|██████████| 844/844 [00:22<00:00, 37.09it/s, Loss=1.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 37, Loss: 1.4911896993198666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 38/50: 100%|██████████| 844/844 [00:22<00:00, 37.03it/s, Loss=1.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 38, Loss: 1.4902453921135004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 39/50: 100%|██████████| 844/844 [00:22<00:00, 37.12it/s, Loss=1.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 39, Loss: 1.4753968945894196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 40/50: 100%|██████████| 844/844 [00:22<00:00, 36.79it/s, Loss=1.47] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 40, Loss: 1.4671429121663786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 41/50: 100%|██████████| 844/844 [00:22<00:00, 37.32it/s, Loss=1.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 41, Loss: 1.4570867501163935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 42/50: 100%|██████████| 844/844 [00:22<00:00, 37.31it/s, Loss=1.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 42, Loss: 1.4434536832486284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 43/50: 100%|██████████| 844/844 [00:22<00:00, 37.10it/s, Loss=1.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 43, Loss: 1.4297177252046305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 44/50: 100%|██████████| 844/844 [00:22<00:00, 37.21it/s, Loss=1.42] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 44, Loss: 1.4202729590696181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 45/50: 100%|██████████| 844/844 [00:22<00:00, 37.22it/s, Loss=1.42] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 45, Loss: 1.4152426417405006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 46/50: 100%|██████████| 844/844 [00:22<00:00, 37.17it/s, Loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 46, Loss: 1.3991631873975998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 47/50: 100%|██████████| 844/844 [00:22<00:00, 37.35it/s, Loss=1.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 47, Loss: 1.3888826094814952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 48/50: 100%|██████████| 844/844 [00:22<00:00, 36.87it/s, Loss=1.38] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 48, Loss: 1.3843155506097875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 49/50: 100%|██████████| 844/844 [00:22<00:00, 37.07it/s, Loss=1.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 49, Loss: 1.3701862273340542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 50/50: 100%|██████████| 844/844 [00:22<00:00, 37.19it/s, Loss=1.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWM JEPA Epoch 50, Loss: 1.3619043339767727\n",
      "Preparando pares SAME/DIFFERENT usando todo el conjunto de entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_220081/3290658403.py:873: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  iwm_predictor.load_state_dict(torch.load('best_iwm_jepa.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando 216000 pares SAME/DIFFERENT para entrenamiento...\n",
      "Preparando pares SAME/DIFFERENT usando todo el conjunto de test...\n",
      "Generando 240000 pares SAME/DIFFERENT para test...\n",
      "Definiendo y entrenando el clasificador SAME/DIFFERENT con características mejoradas...\n",
      "\n",
      "Entrenando clasificador con tasa de aprendizaje: 0.0001\n",
      "Epoch 1, Train Loss: 0.17157928121862587, Val Loss: 0.00990383271899449\n",
      "Epoch 2, Train Loss: 0.017535620199309456, Val Loss: 0.0018073022331127665\n",
      "Epoch 3, Train Loss: 0.006526607850359546, Val Loss: 0.0006189090382313279\n",
      "Epoch 4, Train Loss: 0.0034442176033432285, Val Loss: 0.00026130220045462337\n",
      "Epoch 5, Train Loss: 0.0019421151234699345, Val Loss: 0.0001292352936352526\n",
      "Epoch 6, Train Loss: 0.0012138608668896334, Val Loss: 6.388502128142588e-05\n",
      "Epoch 7, Train Loss: 0.0008742487582343596, Val Loss: 4.104287566368457e-05\n",
      "Epoch 8, Train Loss: 0.0006777666617374591, Val Loss: 2.217688789324609e-05\n",
      "Epoch 9, Train Loss: 0.0005017503572701201, Val Loss: 1.29715134246332e-05\n",
      "Epoch 10, Train Loss: 0.0003750403414435116, Val Loss: 8.097451099323057e-06\n",
      "Epoch 11, Train Loss: 0.00027811505153227633, Val Loss: 4.997189825668672e-06\n",
      "Epoch 12, Train Loss: 0.00017949266152788402, Val Loss: 2.8682332429299532e-06\n",
      "Epoch 13, Train Loss: 0.00015568754675364795, Val Loss: 1.7795504681568334e-06\n",
      "Epoch 14, Train Loss: 0.0001377868303987068, Val Loss: 1.104518184464072e-06\n",
      "Epoch 15, Train Loss: 0.00017536094185440258, Val Loss: 9.121205582808339e-07\n",
      "Epoch 16, Train Loss: 0.00011647189116114599, Val Loss: 5.536115717332103e-07\n",
      "Epoch 17, Train Loss: 0.00013677202961372568, Val Loss: 3.920113683237175e-07\n",
      "Epoch 18, Train Loss: 7.454564227305969e-05, Val Loss: 2.6577425588388016e-07\n",
      "Epoch 19, Train Loss: 5.696993559737436e-05, Val Loss: 2.0196862035269864e-07\n",
      "Epoch 20, Train Loss: 6.449739372800212e-05, Val Loss: 1.5903910534608478e-07\n",
      "Métricas de Validación para lr=0.0001:\n",
      "Accuracy: 1.0\n",
      "F1-score: 1.0\n",
      "ROC-AUC: 1.0\n",
      "PR-AUC: 1.0\n",
      "\n",
      "Entrenando clasificador con tasa de aprendizaje: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gperaltag/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 9.181498461169179e-05, Val Loss: 1.4146165553876548e-08\n",
      "Epoch 2, Train Loss: 3.781738305540919e-05, Val Loss: 7.128195761134357e-09\n",
      "Epoch 3, Train Loss: 0.0001389282121302855, Val Loss: 2.5242053789713585e-08\n",
      "Epoch 4, Train Loss: 0.00010319238678440107, Val Loss: 3.626252220460328e-08\n",
      "Epoch 5, Train Loss: 8.390912891867528e-05, Val Loss: 6.323607865975889e-09\n",
      "Epoch 6, Train Loss: 5.923508150902779e-05, Val Loss: 6.792911347981999e-09\n",
      "Epoch 7, Train Loss: 4.049766957400102e-05, Val Loss: 3.8630520682380235e-09\n",
      "Epoch 8, Train Loss: 4.80391556190322e-05, Val Loss: 5.422559073362387e-09\n",
      "Epoch 9, Train Loss: 2.1144952707059188e-05, Val Loss: 1.977450368802556e-09\n",
      "Epoch 10, Train Loss: 3.179289025222555e-05, Val Loss: 1.918660294087484e-09\n",
      "Epoch 11, Train Loss: 9.571608946830396e-06, Val Loss: 5.786322691537919e-10\n",
      "Epoch 12, Train Loss: 3.3246368384809514e-05, Val Loss: 4.91377986130789e-10\n",
      "Epoch 13, Train Loss: 4.05627004379133e-05, Val Loss: 2.7278377321599747e-10\n",
      "Epoch 14, Train Loss: 5.270764509487717e-05, Val Loss: 2.727837740371683e-10\n",
      "Epoch 15, Train Loss: 7.285494592568713e-05, Val Loss: 6.374133141096751e-10\n",
      "Epoch 16, Train Loss: 0.00014521852123979047, Val Loss: 1.584348534188266e-09\n",
      "Early stopping en el clasificador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_220081/3290658403.py:1112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load('best_classifier.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Validación para lr=0.0003:\n",
      "Accuracy: 1.0\n",
      "F1-score: 1.0\n",
      "ROC-AUC: 1.0\n",
      "PR-AUC: 1.0\n",
      "Evaluando en test Same/Different con el mejor clasificador...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluando en test: 100%|██████████| 938/938 [00:05<00:00, 164.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same/Different Test Metrics (mejor clasificador):\n",
      "Accuracy: 0.9946416666666666\n",
      "F1-score: 0.9946416516331504\n",
      "Precision: 0.9946472178450688\n",
      "Recall: 0.9946416666666666\n",
      "ROC-AUC: 0.9998755543402778\n",
      "PR-AUC: 0.9998763414685661\n",
      "Confusion Matrix:\n",
      "[[119156    844]\n",
      " [   442 119558]]\n",
      "Curvas ROC y Precision-Recall guardadas como 'roc_curve.png' y 'precision_recall_curve.png' respectivamente.\n",
      "Proceso final completado.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torch.optim import Adam, AdamW\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, \n",
    "    confusion_matrix, roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    ")\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning  # Importar ConvergenceWarning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# Configuración de la Semilla para Reproducibilidad\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Establece la semilla para diferentes librerías para asegurar la reproducibilidad.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Valor de la semilla a establecer.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # Garantiza determinismo en cuDNN\n",
    "    torch.backends.cudnn.benchmark = False     # Desactiva el benchmark para evitar variaciones\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Función para inicializar la semilla en los workers de DataLoader\n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Inicializa la semilla para cada worker del DataLoader.\n",
    "\n",
    "    Args:\n",
    "        worker_id (int): Identificador del worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "# Suprimir advertencias específicas si es necesario\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")  # Eliminado para no suprimir ConvergenceWarning\n",
    "\n",
    "############################################################\n",
    "# Dataset Clases\n",
    "############################################################\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Clase personalizada para manejar el conjunto de datos de formas.\n",
    "        Carga imágenes y etiquetas desde un archivo HDF5.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Ruta al archivo HDF5 que contiene los datos.\n",
    "        \"\"\"\n",
    "        with h5py.File(file_path, 'r') as data:\n",
    "            # Cargar y normalizar las imágenes\n",
    "            self.images = torch.tensor(data['images'][:], dtype=torch.float32).div(255.0)\n",
    "            # Cargar las etiquetas\n",
    "            self.labels = torch.tensor(data['labels'][:], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retorna la cantidad total de muestras en el dataset.\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retorna una imagen y su etiqueta correspondiente.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Índice de la muestra a obtener.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (imagen, etiqueta)\n",
    "        \"\"\"\n",
    "        img = self.images[idx].permute(2, 0, 1)  # Cambiar de [H, W, C] a [C, H, W]\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "class DynamicTripletDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"\n",
    "        Clase personalizada para generar tripletes dinámicamente durante el entrenamiento.\n",
    "        Cada triplete consiste en una imagen ancla, una imagen positiva (misma clase) y una imagen negativa (clase diferente).\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): Instancia de ShapesDataset o Subset de ShapesDataset.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        # Verificar si el dataset es una instancia de Subset\n",
    "        if isinstance(dataset, torch.utils.data.Subset):\n",
    "            # Acceder a los labels del dataset original usando los índices del subconjunto\n",
    "            self.labels = dataset.dataset.labels[dataset.indices]\n",
    "        else:\n",
    "            self.labels = dataset.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retorna la cantidad total de muestras en el dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Genera un triplete (ancla, positivo, negativo).\n",
    "\n",
    "        Args:\n",
    "            idx (int): Índice de la muestra ancla.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (ancla, positivo, negativo)\n",
    "        \"\"\"\n",
    "        anchor_img, anchor_label = self.dataset[idx]\n",
    "        shape_val = anchor_label[4].item()  # Suponiendo que la columna 4 es 'shape'\n",
    "\n",
    "        # Encontrar índices con la misma forma\n",
    "        same_shape_indices = (self.labels[:, 4] == shape_val).nonzero(as_tuple=True)[0].numpy()\n",
    "        # Encontrar índices con forma diferente\n",
    "        diff_shape_indices = (self.labels[:, 4] != shape_val).nonzero(as_tuple=True)[0].numpy()\n",
    "\n",
    "        # Asegurarse de que haya suficientes índices para positivos y negativos\n",
    "        if len(same_shape_indices) < 1:\n",
    "            positive_idx = idx  # Usar el mismo índice si no hay otros con la misma forma\n",
    "        else:\n",
    "            positive_idx = np.random.choice(same_shape_indices)\n",
    "\n",
    "        if len(diff_shape_indices) < 1:\n",
    "            negative_idx = idx  # Usar el mismo índice si no hay otros con forma diferente\n",
    "        else:\n",
    "            negative_idx = np.random.choice(diff_shape_indices)\n",
    "\n",
    "        positive_img, _ = self.dataset[positive_idx]\n",
    "        negative_img, _ = self.dataset[negative_idx]\n",
    "        return anchor_img, positive_img, negative_img\n",
    "\n",
    "############################################################\n",
    "# Modelos TAE y TVAE\n",
    "############################################################\n",
    "\n",
    "class TAE(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim):\n",
    "        \"\"\"\n",
    "        Triplet AutoEncoder (TAE).\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Forma de entrada de las imágenes (C, H, W).\n",
    "            latent_dim (int): Dimensionalidad del espacio latente.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*16*16, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64*16*16),\n",
    "            nn.Unflatten(1, (64, 16, 16)),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, input_shape[0], 4, 2, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Paso hacia adelante del modelo.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Entrada de imágenes.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (imagen reconstruida, representación latente)\n",
    "        \"\"\"\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z\n",
    "\n",
    "    def loss(self, x, x_recon, z_anchor, z_positive, z_negative):\n",
    "        \"\"\"\n",
    "        Función de pérdida para TAE que combina la pérdida de reconstrucción y la pérdida triplete.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Imagen original.\n",
    "            x_recon (torch.Tensor): Imagen reconstruida.\n",
    "            z_anchor (torch.Tensor): Representación latente de la imagen ancla.\n",
    "            z_positive (torch.Tensor): Representación latente de la imagen positiva.\n",
    "            z_negative (torch.Tensor): Representación latente de la imagen negativa.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Pérdida total.\n",
    "        \"\"\"\n",
    "        recon_loss = nn.functional.mse_loss(x_recon, x, reduction=\"mean\")\n",
    "        margin = 1.0\n",
    "        pos_dist = torch.norm(z_anchor - z_positive, dim=-1)\n",
    "        neg_dist = torch.norm(z_anchor - z_negative, dim=-1)\n",
    "        triplet_loss = torch.mean(torch.relu(pos_dist - neg_dist + margin))\n",
    "        return recon_loss + triplet_loss\n",
    "\n",
    "class TVAE(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim):\n",
    "        \"\"\"\n",
    "        Triplet Variational AutoEncoder (TVAE).\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Forma de entrada de las imágenes (C, H, W).\n",
    "            latent_dim (int): Dimensionalidad del espacio latente.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*16*16, latent_dim*2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64*16*16),\n",
    "            nn.Unflatten(1, (64, 16, 16)),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, input_shape[0], 4, 2, 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Reparametrización para el TVAE.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor): Media de la distribución latente.\n",
    "            log_var (torch.Tensor): Log-variancia de la distribución latente.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Muestra reparametrizada de la distribución latente.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Paso hacia adelante del modelo.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Entrada de imágenes.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (imagen reconstruida, mu, log_var, representación latente)\n",
    "        \"\"\"\n",
    "        q = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(q, 2, dim=-1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, log_var, z\n",
    "\n",
    "    def loss(self, x, x_recon, mu, log_var, z_anchor, z_positive, z_negative):\n",
    "        \"\"\"\n",
    "        Función de pérdida para TVAE que combina la pérdida de reconstrucción, la pérdida KL y la pérdida triplete.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Imagen original.\n",
    "            x_recon (torch.Tensor): Imagen reconstruida.\n",
    "            mu (torch.Tensor): Media de la distribución latente.\n",
    "            log_var (torch.Tensor): Log-variancia de la distribución latente.\n",
    "            z_anchor (torch.Tensor): Representación latente de la imagen ancla.\n",
    "            z_positive (torch.Tensor): Representación latente de la imagen positiva.\n",
    "            z_negative (torch.Tensor): Representación latente de la imagen negativa.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Pérdida total.\n",
    "        \"\"\"\n",
    "        recon_loss = nn.functional.mse_loss(x_recon, x, reduction=\"mean\")\n",
    "        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        margin = 1.0\n",
    "        pos_dist = torch.norm(z_anchor - z_positive, dim=-1)\n",
    "        neg_dist = torch.norm(z_anchor - z_negative, dim=-1)\n",
    "        triplet_loss = torch.mean(torch.relu(pos_dist - neg_dist + margin))\n",
    "        return recon_loss + kl_loss + triplet_loss\n",
    "\n",
    "############################################################\n",
    "# Entrenamiento y guardado\n",
    "############################################################\n",
    "\n",
    "def train_model(model, dataloader, optimizer, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Entrena el modelo utilizando los datos proporcionados.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Modelo a entrenar.\n",
    "        dataloader (DataLoader): DataLoader que proporciona los datos.\n",
    "        optimizer (torch.optim.Optimizer): Optimizador para actualizar los pesos del modelo.\n",
    "        device (torch.device): Dispositivo (CPU o GPU) para entrenar el modelo.\n",
    "        epochs (int, optional): Número de épocas de entrenamiento. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Modelo entrenado.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for anchor, positive, negative in pbar:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if isinstance(model, TAE):\n",
    "                x_recon, z_anchor = model(anchor)\n",
    "                _, z_positive = model(positive)\n",
    "                _, z_negative = model(negative)\n",
    "                loss = model.loss(anchor, x_recon, z_anchor, z_positive, z_negative)\n",
    "            elif isinstance(model, TVAE):\n",
    "                x_recon, mu, log_var, z_anchor = model(anchor)\n",
    "                _, _, _, z_positive = model(positive)\n",
    "                _, _, _, z_negative = model(negative)\n",
    "                loss = model.loss(anchor, x_recon, mu, log_var, z_anchor, z_positive, z_negative)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": epoch_loss / len(dataloader)})\n",
    "    return model\n",
    "\n",
    "def save_representations(model, dataset, device, save_path):\n",
    "    \"\"\"\n",
    "    Guarda las representaciones latentes y las etiquetas del dataset proporcionado.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Modelo entrenado para generar las representaciones latentes.\n",
    "        dataset (Dataset): Dataset del cual generar las representaciones.\n",
    "        device (torch.device): Dispositivo para procesar los datos.\n",
    "        save_path (str): Ruta donde guardar las representaciones.\n",
    "    \"\"\"\n",
    "    latents = []\n",
    "    factors = []\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=1024, shuffle=False, worker_init_fn=worker_init_fn)\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(loader, desc=f\"Saving {save_path}\"):\n",
    "            img = img.to(device)\n",
    "            if isinstance(model, TAE):\n",
    "                _, z = model(img)\n",
    "            elif isinstance(model, TVAE):\n",
    "                _, mu, log_var, z = model(img)\n",
    "            latents.append(z.cpu().numpy())\n",
    "            factors.append(label.numpy())\n",
    "    latents = np.vstack(latents)\n",
    "    factors = np.vstack(factors)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump({\"latents\": latents, \"factors\": factors}, f)\n",
    "    print(f\"Representations saved to {save_path}\")\n",
    "\n",
    "############################################################\n",
    "# MIG y DCI\n",
    "############################################################\n",
    "\n",
    "def compute_mig(latents, factors, num_bins=10):  # Reducido de 20 a 10\n",
    "    \"\"\"\n",
    "    Calcula la métrica Mutual Information Gap (MIG) para evaluar la calidad de las representaciones latentes.\n",
    "\n",
    "    Args:\n",
    "        latents (np.ndarray): Representaciones latentes del modelo.\n",
    "        factors (np.ndarray): Factores de variación originales.\n",
    "        num_bins (int, optional): Número de bins para discretizar las representaciones. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor promedio de MIG.\n",
    "    \"\"\"\n",
    "    num_factors = factors.shape[1]\n",
    "    num_latents = latents.shape[1]\n",
    "\n",
    "    est_lat = KBinsDiscretizer(n_bins=num_bins, encode='ordinal', strategy='quantile')\n",
    "    lat_disc = est_lat.fit_transform(latents).astype(int)\n",
    "\n",
    "    factors_disc = []\n",
    "    for f_idx in range(num_factors):\n",
    "        f_vals = factors[:, f_idx]\n",
    "        uniq = np.unique(f_vals)\n",
    "        if len(uniq) > 10:\n",
    "            est_f = KBinsDiscretizer(n_bins=min(num_bins, len(uniq)), encode='ordinal', strategy='quantile')\n",
    "            f_disc = est_f.fit_transform(f_vals.reshape(-1, 1)).astype(int).flatten()\n",
    "        else:\n",
    "            val2idx = {val: i for i, val in enumerate(np.sort(uniq))}\n",
    "            f_disc = np.array([val2idx[v] for v in f_vals])\n",
    "        factors_disc.append(f_disc)\n",
    "    factors_disc = np.stack(factors_disc, axis=1).astype(int)\n",
    "\n",
    "    def mutual_information(z, v):\n",
    "        pz = np.bincount(z) / len(z)\n",
    "        pv = np.bincount(v) / len(v)\n",
    "        pzv, _, _ = np.histogram2d(z, v, bins=(np.arange(z.max()+2)-0.5, np.arange(v.max()+2)-0.5))\n",
    "        pzv = pzv / pzv.sum()\n",
    "        mi = 0\n",
    "        nz, nv = pzv.shape\n",
    "        for i in range(nz):\n",
    "            for j in range(nv):\n",
    "                if pzv[i, j] > 0:\n",
    "                    mi += pzv[i, j] * math.log(pzv[i, j] / (pz[i] * pv[j] + 1e-12) + 1e-12)\n",
    "        return mi / math.log(2 + 1e-9)\n",
    "\n",
    "    def entropy(v):\n",
    "        pv = np.bincount(v) / len(v)\n",
    "        h = 0\n",
    "        for p in pv:\n",
    "            if p > 0:\n",
    "                h -= p * math.log(p + 1e-12)\n",
    "        return h / math.log(2 + 1e-9)\n",
    "\n",
    "    migs = []\n",
    "    for f_idx in range(num_factors):\n",
    "        v = factors_disc[:, f_idx]\n",
    "        h_v = entropy(v)\n",
    "        mi_scores = []\n",
    "        for z_j in range(num_latents):\n",
    "            z = lat_disc[:, z_j]\n",
    "            mi_scores.append(mutual_information(z, v))\n",
    "        mi_scores = sorted(mi_scores, reverse=True)\n",
    "        if len(mi_scores) > 1:\n",
    "            migs.append((mi_scores[0] - mi_scores[1]) / (h_v + 1e-12))\n",
    "        else:\n",
    "            migs.append(mi_scores[0] / (h_v + 1e-12))\n",
    "    return np.mean(migs)\n",
    "\n",
    "def compute_dci(latents, factors):\n",
    "    \"\"\"\n",
    "    Calcula la métrica Disentanglement Completeness Informativeness (DCI) para evaluar la calidad de las representaciones latentes.\n",
    "\n",
    "    Args:\n",
    "        latents (np.ndarray): Representaciones latentes del modelo.\n",
    "        factors (np.ndarray): Factores de variación originales.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor promedio de DCI.\n",
    "    \"\"\"\n",
    "    num_factors = factors.shape[1]\n",
    "    disent_scores = []\n",
    "    scaler = StandardScaler()  # Escalador para las representaciones latentes\n",
    "    latents_scaled = scaler.fit_transform(latents)  # Escalar solo una vez para todo el proceso\n",
    "\n",
    "    for f_idx in range(num_factors):\n",
    "        f_vals = factors[:, f_idx]\n",
    "        uniq = np.unique(f_vals)\n",
    "        if len(uniq) > 10:\n",
    "            model = Ridge(alpha=1.0)\n",
    "            model.fit(latents_scaled, f_vals)\n",
    "            coefs = model.coef_\n",
    "        else:\n",
    "            val2idx = {val: i for i, val in enumerate(np.sort(uniq))}\n",
    "            y_disc = np.array([val2idx[v] for v in f_vals])\n",
    "            model = LogisticRegression(max_iter=1000, multi_class='auto')  # Aumentado max_iter a 1000\n",
    "            model.fit(latents_scaled, y_disc)\n",
    "            coefs = model.coef_\n",
    "            if coefs.shape[0] > 1:\n",
    "                coefs = np.mean(np.abs(coefs), axis=0)\n",
    "            else:\n",
    "                coefs = coefs.flatten()\n",
    "        importances = np.abs(coefs)\n",
    "        p = importances / (importances.sum() + 1e-12)\n",
    "        entropy_val = -np.sum(p * np.log(p + 1e-12))\n",
    "        max_entropy = math.log(len(p) + 1e-12)\n",
    "        disent = 1 - (entropy_val / (max_entropy + 1e-12))\n",
    "        disent_scores.append(disent)\n",
    "    return np.mean(disent_scores)\n",
    "\n",
    "############################################################\n",
    "# create_stratified_pairs\n",
    "############################################################\n",
    "\n",
    "def create_stratified_pairs(x, y, num_pairs):\n",
    "    \"\"\"\n",
    "    Crea pares de imágenes estratificados en dos clases:\n",
    "    SAME: ambas imágenes tienen la misma forma (y[:,4] igual)\n",
    "    DIFFERENT: las imágenes tienen distinta forma (y[:,4] distinto)\n",
    "\n",
    "    Genera la mitad de pares SAME y la mitad DIFFERENT.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Tensores de imágenes [N, C, H, W].\n",
    "        y (torch.Tensor): Tensores de etiquetas [N, num_factors].\n",
    "        num_pairs (int): Número total de pares a generar.\n",
    "\n",
    "    Returns:\n",
    "        tuple: ([X1, X2], y_pairs)\n",
    "    \"\"\"\n",
    "    shape_labels = y[:,4].cpu().numpy()  # El factor de la forma está en la columna 4\n",
    "    unique_shapes = np.unique(shape_labels)\n",
    "    shape_to_indices = {sh: np.where(shape_labels == sh)[0] for sh in unique_shapes}\n",
    "\n",
    "    half_pairs = num_pairs // 2\n",
    "\n",
    "    # Generar pares SAME\n",
    "    same_x1 = []\n",
    "    same_x2 = []\n",
    "    for _ in range(half_pairs):\n",
    "        sh = np.random.choice(unique_shapes)\n",
    "        inds = shape_to_indices[sh]\n",
    "        if len(inds) < 2:\n",
    "            continue\n",
    "        i1, i2 = np.random.choice(inds, 2, replace=False)\n",
    "        same_x1.append(i1)\n",
    "        same_x2.append(i2)\n",
    "\n",
    "    # Generar pares DIFFERENT\n",
    "    diff_x1 = []\n",
    "    diff_x2 = []\n",
    "    for _ in range(half_pairs):\n",
    "        if len(unique_shapes) < 2:\n",
    "            break\n",
    "        sh1, sh2 = np.random.choice(unique_shapes, 2, replace=False)\n",
    "        inds1 = shape_to_indices[sh1]\n",
    "        inds2 = shape_to_indices[sh2]\n",
    "        if len(inds1) == 0 or len(inds2) == 0:\n",
    "            continue\n",
    "        i1 = np.random.choice(inds1)\n",
    "        i2 = np.random.choice(inds2)\n",
    "        diff_x1.append(i1)\n",
    "        diff_x2.append(i2)\n",
    "\n",
    "    same_x1 = np.array(same_x1)\n",
    "    same_x2 = np.array(same_x2)\n",
    "    diff_x1 = np.array(diff_x1)\n",
    "    diff_x2 = np.array(diff_x2)\n",
    "\n",
    "    # Ajustar por si alguno se quedó corto\n",
    "    min_len = min(len(same_x1), len(diff_x1))\n",
    "    if min_len == 0:\n",
    "        raise ValueError(\"No hay suficientes pares para generar.\")\n",
    "    same_x1 = same_x1[:min_len]\n",
    "    same_x2 = same_x2[:min_len]\n",
    "    diff_x1 = diff_x1[:min_len]\n",
    "    diff_x2 = diff_x2[:min_len]\n",
    "\n",
    "    X1 = np.concatenate([same_x1, diff_x1])\n",
    "    X2 = np.concatenate([same_x2, diff_x2])\n",
    "\n",
    "    # Mantener los datos en CPU\n",
    "    X1_t = x[X1].cpu()\n",
    "    X2_t = x[X2].cpu()\n",
    "\n",
    "    # Crear etiquetas: 0 para SAME, 1 para DIFFERENT\n",
    "    y_pairs = torch.cat([\n",
    "        torch.zeros(min_len, dtype=torch.long),\n",
    "        torch.ones(min_len, dtype=torch.long)\n",
    "    ])\n",
    "\n",
    "    x_pairs = [X1_t, X2_t]\n",
    "    return x_pairs, y_pairs\n",
    "\n",
    "############################################################\n",
    "# JEPA Predictor\n",
    "############################################################\n",
    "\n",
    "class IWM_JEPA_Predictor(nn.Module):\n",
    "    def __init__(self, latent_dim=6, action_dim=4):\n",
    "        \"\"\"\n",
    "        Predictor IWM JEPA que predice la representación latente futura basada en la actual y en ciertas acciones.\n",
    "\n",
    "        Args:\n",
    "            latent_dim (int, optional): Dimensionalidad del espacio latente. Defaults to 6.\n",
    "            action_dim (int, optional): Dimensionalidad de los parámetros de acción. Defaults to 4.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim + action_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z_x, a_xy):\n",
    "        \"\"\"\n",
    "        Paso hacia adelante del predictor.\n",
    "\n",
    "        Args:\n",
    "            z_x (torch.Tensor): Representación latente actual.\n",
    "            a_xy (torch.Tensor): Parámetros de acción.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Representación latente predicha.\n",
    "        \"\"\"\n",
    "        inp = torch.cat([z_x, a_xy], dim=1)\n",
    "        return self.mlp(inp)\n",
    "\n",
    "def iwm_jepa_loss(z_pred, z_y):\n",
    "    \"\"\"\n",
    "    Función de pérdida para el predictor IWM JEPA.\n",
    "\n",
    "    Args:\n",
    "        z_pred (torch.Tensor): Representación latente predicha.\n",
    "        z_y (torch.Tensor): Representación latente real.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Pérdida MSE.\n",
    "    \"\"\"\n",
    "    return nn.functional.mse_loss(z_pred, z_y)\n",
    "\n",
    "############################################################\n",
    "# Funciones para IWM JEPA\n",
    "############################################################\n",
    "\n",
    "def generate_views_for_iwm(imgs, device):\n",
    "    \"\"\"\n",
    "    Genera dos vistas de cada imagen: una con leves transformaciones y otra con transformaciones más fuertes.\n",
    "\n",
    "    Args:\n",
    "        imgs (torch.Tensor): Batch de imágenes [B, C, H, W].\n",
    "        device (torch.device): Dispositivo para procesar las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x_imgs, y_imgs)\n",
    "    \"\"\"\n",
    "    B = imgs.shape[0]\n",
    "    def color_jitter(img, brightness=0.2, contrast=0.2):\n",
    "        \"\"\"\n",
    "        Aplica jitter de color a una imagen.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Imagen [1, C, H, W].\n",
    "            brightness (float, optional): Factor de brillo. Defaults to 0.2.\n",
    "            contrast (float, optional): Factor de contraste. Defaults to 0.2.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Imagen transformada.\n",
    "        \"\"\"\n",
    "        b_factor = 1.0 + (2 * random.random() - 1) * brightness\n",
    "        c_factor = 1.0 + (2 * random.random() - 1) * contrast\n",
    "        mean_img = img.mean(dim=(1,2,3), keepdim=True)\n",
    "        img2 = img * b_factor\n",
    "        img2 = (img2 - mean_img) * c_factor + mean_img\n",
    "        img2 = torch.clamp(img2, 0, 1)\n",
    "        return img2\n",
    "\n",
    "    # y_imgs con leve jitter\n",
    "    y_imgs = []\n",
    "    for i in range(B):\n",
    "        y_imgs.append(color_jitter(imgs[i:i+1], 0.1, 0.1))\n",
    "    y_imgs = torch.cat(y_imgs, dim=0)\n",
    "\n",
    "    # x con fuerte jitter+blur+mask\n",
    "    x_imgs = []\n",
    "    for i in range(B):\n",
    "        x_img = imgs[i:i+1]\n",
    "        x_img = color_jitter(x_img, 0.4, 0.4)\n",
    "        if random.random() < 0.5:\n",
    "            kernel = 3\n",
    "            pad = (kernel - 1) // 2\n",
    "            x_img = torch.nn.functional.avg_pool2d(x_img, kernel, stride=1, padding=pad)\n",
    "        if random.random() < 0.5:\n",
    "            C, H, W = x_img.shape[1], x_img.shape[2], x_img.shape[3]\n",
    "            mh, mw = H // 4, W // 4\n",
    "            sy = random.randint(0, H - mh)\n",
    "            sx = random.randint(0, W - mw)\n",
    "            x_img[:, :, sy:sy+mh, sx:sx+mw] = 0.0\n",
    "        x_imgs.append(x_img)\n",
    "    x_imgs = torch.cat(x_imgs, dim=0)\n",
    "    return x_imgs.to(device), y_imgs.to(device)\n",
    "\n",
    "def generate_action_params(x_imgs, y_imgs):\n",
    "    \"\"\"\n",
    "    Genera parámetros de acción basados en las diferencias de brillo y contraste entre x_imgs y y_imgs.\n",
    "\n",
    "    Args:\n",
    "        x_imgs (torch.Tensor): Primer conjunto de imágenes [B, C, H, W].\n",
    "        y_imgs (torch.Tensor): Segundo conjunto de imágenes [B, C, H, W].\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Parámetros de acción [B, 4].\n",
    "    \"\"\"\n",
    "    B = x_imgs.shape[0]\n",
    "    def brightness_contrast(img):\n",
    "        \"\"\"\n",
    "        Calcula el brillo y contraste de una imagen.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Imagen [B, C, H, W].\n",
    "\n",
    "        Returns:\n",
    "            tuple: (brillo medio, desviación estándar)\n",
    "        \"\"\"\n",
    "        mean_val = img.mean(dim=(1,2,3))\n",
    "        std_val = img.std(dim=(1,2,3)) + 1e-6\n",
    "        return mean_val, std_val\n",
    "    mean_x, std_x = brightness_contrast(x_imgs)\n",
    "    mean_y, std_y = brightness_contrast(y_imgs)\n",
    "    a_xy = torch.stack([mean_y - mean_x, std_y - std_x, torch.zeros_like(mean_x), torch.zeros_like(mean_x)], dim=1)\n",
    "    return a_xy\n",
    "\n",
    "############################################################\n",
    "# MAIN\n",
    "############################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración del dispositivo y parámetros\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    latent_dim = 6\n",
    "\n",
    "    # Cargar los datasets de entrenamiento y prueba\n",
    "    train_dataset_full = ShapesDataset('/home/gperaltag/3dshapes_data/3dshapes_abstraction_train.h5')\n",
    "    test_dataset = ShapesDataset('/home/gperaltag/3dshapes_data/3dshapes_abstraction_test.h5')\n",
    "\n",
    "    # ============================\n",
    "    # Crear Conjunto de Validación\n",
    "    # ============================\n",
    "    val_size = int(0.1 * len(train_dataset_full))  # 10% para validación\n",
    "    train_size = len(train_dataset_full) - val_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset_full, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "    print(f\"Train size: {train_size}, Validation size: {val_size}\")\n",
    "\n",
    "    # ============================\n",
    "    # Etapa 1: Entrenar TAE y TVAE\n",
    "    # ============================\n",
    "    # Crear el dataset triplet para entrenamiento\n",
    "    triplet_dataset = DynamicTripletDataset(train_dataset)\n",
    "    triplet_loader = DataLoader(\n",
    "        triplet_dataset,\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "\n",
    "    # Entrenar TAE\n",
    "    print(\"Entrenando TAE...\")\n",
    "    tae = TAE((3, 64, 64), latent_dim).to(device)\n",
    "    tae_optimizer = Adam(tae.parameters(), lr=1e-4)\n",
    "    train_model(tae, triplet_loader, tae_optimizer, device, epochs=10)\n",
    "    save_representations(tae, test_dataset, device, \"tae_representations.pkl\")\n",
    "\n",
    "    # Entrenar TVAE\n",
    "    print(\"Entrenando TVAE...\")\n",
    "    tvae = TVAE((3, 64, 64), latent_dim).to(device)\n",
    "    tvae_optimizer = Adam(tvae.parameters(), lr=1e-4)  # Corregido para usar tvae.parameters()\n",
    "    train_model(tvae, triplet_loader, tvae_optimizer, device, epochs=10)\n",
    "    save_representations(tvae, test_dataset, device, \"tvae_representations.pkl\")\n",
    "\n",
    "    # ============================\n",
    "    # Evaluar MIG y DCI\n",
    "    # ============================\n",
    "    print(\"Evaluando MIG y DCI para TAE y TVAE...\")\n",
    "    with open(\"tae_representations.pkl\", \"rb\") as f:\n",
    "        tae_data = pickle.load(f)\n",
    "    tae_latents = tae_data[\"latents\"]\n",
    "    tae_factors = tae_data[\"factors\"]\n",
    "\n",
    "    with open(\"tvae_representations.pkl\", \"rb\") as f:\n",
    "        tvae_data = pickle.load(f)\n",
    "    tvae_latents = tvae_data[\"latents\"]\n",
    "    tvae_factors = tvae_data[\"factors\"]\n",
    "\n",
    "    tae_mig = compute_mig(tae_latents, tae_factors)\n",
    "    tae_dci = compute_dci(tae_latents, tae_factors)\n",
    "    tvae_mig = compute_mig(tvae_latents, tvae_factors)\n",
    "    tvae_dci = compute_dci(tvae_latents, tvae_factors)\n",
    "\n",
    "    print(f\"TAE MIG: {tae_mig}, TAE DCI: {tae_dci}\")\n",
    "    print(f\"TVAE MIG: {tvae_mig}, TVAE DCI: {tvae_dci}\")\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MIG + DCI\n",
    "    tae_score = tae_mig + tae_dci\n",
    "    tvae_score = tvae_mig + tvae_dci\n",
    "    if tvae_score > tae_score:\n",
    "        best_model_name = \"TVAE\"\n",
    "        best_encoder = tvae.encoder\n",
    "    else:\n",
    "        best_model_name = \"TAE\"\n",
    "        best_encoder = tae.encoder\n",
    "\n",
    "    print(f\"Best model for IWM JEPA: {best_model_name}\")\n",
    "\n",
    "    def get_latent(z):\n",
    "        \"\"\"\n",
    "        Obtiene la representación latente correcta según el modelo seleccionado.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Representación latente del modelo.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Representación latente utilizada.\n",
    "        \"\"\"\n",
    "        if best_model_name == \"TVAE\":\n",
    "            return z[:, :latent_dim]\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "    # Congelar encoder seleccionado (f_theta)\n",
    "    f_theta = best_encoder\n",
    "    for param in f_theta.parameters():\n",
    "        param.requires_grad = False\n",
    "    f_theta.eval()\n",
    "\n",
    "    # Crear f_EMA_theta como copia congelada\n",
    "    f_EMA_theta = copy.deepcopy(f_theta)\n",
    "    for param in f_EMA_theta.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # ============================\n",
    "    # Etapa 2: Entrenar IWM JEPA\n",
    "    # ============================\n",
    "    print(\"Entrenando IWM JEPA Predictor...\")\n",
    "    iwm_predictor = IWM_JEPA_Predictor(latent_dim=latent_dim, action_dim=4).to(device)\n",
    "    iwm_optimizer = AdamW(iwm_predictor.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    # === MODIFICACIÓN AQUÍ ===\n",
    "    # Antes: iwm_loader = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    # Ahora: Utilizar train_dataset en lugar de test_dataset\n",
    "    iwm_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "    # ============================\n",
    "\n",
    "    # Aumentar el número de épocas y aplicar Early Stopping\n",
    "    epochs_iwm = 50\n",
    "    best_loss = float('inf')\n",
    "    patience = 3\n",
    "    trigger_times = 0\n",
    "    # Utilizar un scheduler para ajustar la tasa de aprendizaje\n",
    "    scheduler_iwm = torch.optim.lr_scheduler.ReduceLROnPlateau(iwm_optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs_iwm):\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(iwm_loader, desc=f\"IWM JEPA Epoch {epoch+1}/{epochs_iwm}\")\n",
    "        for imgs, labels in pbar:\n",
    "            imgs = imgs.to(device)\n",
    "            x_imgs, y_imgs = generate_views_for_iwm(imgs, device)\n",
    "            with torch.no_grad():\n",
    "                z_x = f_theta(x_imgs)\n",
    "                z_y = f_EMA_theta(y_imgs)\n",
    "                z_x = get_latent(z_x)\n",
    "                z_y = get_latent(z_y)\n",
    "            a_xy = generate_action_params(x_imgs, y_imgs)\n",
    "            iwm_optimizer.zero_grad()\n",
    "            z_pred = iwm_predictor(z_x, a_xy)\n",
    "            loss = iwm_jepa_loss(z_pred, z_y)\n",
    "            loss.backward()\n",
    "            iwm_optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": epoch_loss / len(iwm_loader)})\n",
    "        avg_loss = epoch_loss / len(iwm_loader)\n",
    "        scheduler_iwm.step(avg_loss)\n",
    "        print(f\"IWM JEPA Epoch {epoch+1}, Loss: {avg_loss}\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            trigger_times = 0\n",
    "            torch.save(iwm_predictor.state_dict(), 'best_iwm_jepa.pth')\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping en IWM JEPA\")\n",
    "                break\n",
    "\n",
    "    # Cargar el mejor modelo entrenado\n",
    "    iwm_predictor.load_state_dict(torch.load('best_iwm_jepa.pth'))\n",
    "    iwm_predictor.eval()\n",
    "\n",
    "    # ============================\n",
    "    # Etapa 3: Same/Different\n",
    "    # ============================\n",
    "    print(\"Preparando pares SAME/DIFFERENT usando todo el conjunto de entrenamiento...\")\n",
    "    # Usar todo el conjunto de entrenamiento\n",
    "    train_loader_full = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1024,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "    all_train_imgs = []\n",
    "    all_train_factors = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in train_loader_full:\n",
    "            all_train_imgs.append(img)\n",
    "            all_train_factors.append(label)\n",
    "    all_train_imgs = torch.cat(all_train_imgs, dim=0)  # [N, C, H, W]\n",
    "    all_train_factors = torch.cat(all_train_factors, dim=0)  # [N, num_factors]\n",
    "\n",
    "    # Generar pares usando todas las imágenes de entrenamiento\n",
    "    train_num_pairs = len(all_train_imgs)\n",
    "    print(f\"Generando {train_num_pairs} pares SAME/DIFFERENT para entrenamiento...\")\n",
    "    x_pairs_train, y_pairs_train = create_stratified_pairs(all_train_imgs, all_train_factors, num_pairs=train_num_pairs)\n",
    "\n",
    "    # La clase same/diff ya está definida como 0 (SAME) y 1 (DIFFERENT)\n",
    "    same_diff_labels_train = y_pairs_train  # 0 o 1\n",
    "\n",
    "    # Crear dataset de Same/Different\n",
    "    train_sd_dataset = TensorDataset(x_pairs_train[0], x_pairs_train[1], same_diff_labels_train)\n",
    "\n",
    "    # Dividir en train y validación para el clasificador *}*\n",
    "    train_sd_size = int(0.8 * len(train_sd_dataset))\n",
    "    val_sd_size = len(train_sd_dataset) - train_sd_size\n",
    "    train_sd, val_sd = random_split(train_sd_dataset, [train_sd_size, val_sd_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    train_sd_dataloader = DataLoader(\n",
    "        train_sd,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "\n",
    "    val_sd_dataloader = DataLoader(\n",
    "        val_sd,\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "\n",
    "    # Preparar pares SAME/DIFFERENT para test\n",
    "    print(\"Preparando pares SAME/DIFFERENT usando todo el conjunto de test...\")\n",
    "    test_loader_full = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "    all_test_imgs = []\n",
    "    all_test_factors = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_loader_full:\n",
    "            all_test_imgs.append(img)\n",
    "            all_test_factors.append(label)\n",
    "    all_test_imgs = torch.cat(all_test_imgs, dim=0)  # [N, C, H, W]\n",
    "    all_test_factors = torch.cat(all_test_factors, dim=0)  # [N, num_factors]\n",
    "\n",
    "    test_num_pairs = len(all_test_imgs)\n",
    "    print(f\"Generando {test_num_pairs} pares SAME/DIFFERENT para test...\")\n",
    "    x_pairs_test, y_pairs_test = create_stratified_pairs(all_test_imgs, all_test_factors, num_pairs=test_num_pairs)\n",
    "    same_diff_labels_test = y_pairs_test  # 0 o 1\n",
    "\n",
    "    test_sd_dataset = TensorDataset(x_pairs_test[0], x_pairs_test[1], same_diff_labels_test)\n",
    "    test_sd_dataloader = DataLoader(\n",
    "        test_sd_dataset,\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn  # Asegurar reproducibilidad en los workers\n",
    "    )\n",
    "\n",
    "    # ============================\n",
    "    # Definir y Entrenar el Clasificador Same/Different\n",
    "    # ============================\n",
    "    print(\"Definiendo y entrenando el clasificador SAME/DIFFERENT con características mejoradas...\")\n",
    "    concatenated_feature_dim = 3 * latent_dim  # z1, z2, z_pred - z2\n",
    "\n",
    "    # Definir una arquitectura más compleja para el clasificador\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(concatenated_feature_dim, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(64, 2)  # Output: 2 clases (SAME, DIFFERENT)\n",
    "    ).to(device)\n",
    "\n",
    "    # Probar diferentes tasas de aprendizaje\n",
    "    learning_rates = [1e-4, 3e-4]\n",
    "    best_clf_metrics = {'accuracy': 0, 'f1': 0, 'roc_auc': 0, 'pr_auc': 0}\n",
    "    best_clf_state = None\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\nEntrenando clasificador con tasa de aprendizaje: {lr}\")\n",
    "        clf_optimizer = AdamW(classifier.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        clf_loss = nn.CrossEntropyLoss()\n",
    "        scheduler_clf = torch.optim.lr_scheduler.ReduceLROnPlateau(clf_optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "        # Early Stopping\n",
    "        epochs_clf = 20\n",
    "        best_val_loss = float('inf')\n",
    "        patience_clf = 3\n",
    "        trigger_times_clf = 0\n",
    "\n",
    "        for epoch in range(epochs_clf):\n",
    "            # Entrenar\n",
    "            classifier.train()\n",
    "            epoch_loss = 0\n",
    "            for x1_batch, x2_batch, sd_label in train_sd_dataloader:\n",
    "                x1_batch, x2_batch, sd_label = x1_batch.to(device), x2_batch.to(device), sd_label.to(device)\n",
    "                with torch.no_grad():\n",
    "                    z1 = f_theta(x1_batch)\n",
    "                    z2 = f_theta(x2_batch)\n",
    "                    z_pred = iwm_predictor(z1, generate_action_params(x1_batch, x2_batch))\n",
    "                    # Obtener las representaciones latentes\n",
    "                    z1 = get_latent(z1)\n",
    "                    z2 = get_latent(z2)\n",
    "                    z_pred_minus_z2 = z_pred - z2\n",
    "                    # Concatenar las características\n",
    "                    features = torch.cat([z1, z2, z_pred_minus_z2], dim=1)  # [batch_size, 3 * latent_dim]\n",
    "                clf_optimizer.zero_grad()\n",
    "                logits = classifier(features)\n",
    "                loss = clf_loss(logits, sd_label)\n",
    "                loss.backward()\n",
    "                clf_optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            avg_train_loss = epoch_loss / len(train_sd_dataloader)\n",
    "\n",
    "            # Validar\n",
    "            classifier.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x1_val, x2_val, sd_label_val in val_sd_dataloader:\n",
    "                    x1_val, x2_val, sd_label_val = x1_val.to(device), x2_val.to(device), sd_label_val.to(device)\n",
    "                    z1 = f_theta(x1_val)\n",
    "                    z2 = f_theta(x2_val)\n",
    "                    z_pred = iwm_predictor(z1, generate_action_params(x1_val, x2_val))\n",
    "                    z1 = get_latent(z1)\n",
    "                    z2 = get_latent(z2)\n",
    "                    z_pred_minus_z2 = z_pred - z2\n",
    "                    features = torch.cat([z1, z2, z_pred_minus_z2], dim=1)  # [batch_size, 3 * latent_dim]\n",
    "                    logits = classifier(features)\n",
    "                    loss = clf_loss(logits, sd_label_val)\n",
    "                    val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(val_sd_dataloader)\n",
    "            scheduler_clf.step(avg_val_loss)\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "            # Early Stopping\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                trigger_times_clf = 0\n",
    "                best_clf_state = copy.deepcopy(classifier.state_dict())\n",
    "            else:\n",
    "                trigger_times_clf += 1\n",
    "                if trigger_times_clf >= patience_clf:\n",
    "                    print(\"Early stopping en el clasificador\")\n",
    "                    break\n",
    "\n",
    "        # Cargar el mejor estado del clasificador para esta tasa de aprendizaje\n",
    "        if best_clf_state is not None:\n",
    "            classifier.load_state_dict(best_clf_state)\n",
    "\n",
    "        # Evaluar en el conjunto de validación\n",
    "        classifier.eval()\n",
    "        all_val_preds = []\n",
    "        all_val_trues = []\n",
    "        all_val_probs = []\n",
    "        with torch.no_grad():\n",
    "            for x1_val, x2_val, sd_label_val in val_sd_dataloader:\n",
    "                x1_val, x2_val, sd_label_val = x1_val.to(device), x2_val.to(device), sd_label_val.to(device)\n",
    "                z1 = f_theta(x1_val)\n",
    "                z2 = f_theta(x2_val)\n",
    "                z_pred = iwm_predictor(z1, generate_action_params(x1_val, x2_val))\n",
    "                z1 = get_latent(z1)\n",
    "                z2 = get_latent(z2)\n",
    "                z_pred_minus_z2 = z_pred - z2\n",
    "                features = torch.cat([z1, z2, z_pred_minus_z2], dim=1)\n",
    "                logits = classifier(features)\n",
    "                probs = torch.softmax(logits, dim=1)[:,1]  # Probabilidad de la clase 'DIFFERENT'\n",
    "                preds = logits.argmax(dim=1)\n",
    "                all_val_preds.append(preds.cpu().numpy())\n",
    "                all_val_trues.append(sd_label_val.cpu().numpy())\n",
    "                all_val_probs.append(probs.cpu().numpy())\n",
    "        all_val_preds = np.concatenate(all_val_preds)\n",
    "        all_val_trues = np.concatenate(all_val_trues)\n",
    "        all_val_probs = np.concatenate(all_val_probs)\n",
    "\n",
    "        # Calcular métricas\n",
    "        acc = accuracy_score(all_val_trues, all_val_preds)\n",
    "        f1 = f1_score(all_val_trues, all_val_preds, average='weighted')\n",
    "        roc_auc = roc_auc_score(all_val_trues, all_val_probs)\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(all_val_trues, all_val_probs)\n",
    "        pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "        print(f\"Métricas de Validación para lr={lr}:\")\n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        print(f\"F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {roc_auc}\")\n",
    "        print(f\"PR-AUC: {pr_auc}\")\n",
    "\n",
    "        # Guardar las mejores métricas\n",
    "        if roc_auc > best_clf_metrics['roc_auc']:\n",
    "            best_clf_metrics['accuracy'] = acc\n",
    "            best_clf_metrics['f1'] = f1\n",
    "            best_clf_metrics['roc_auc'] = roc_auc\n",
    "            best_clf_metrics['pr_auc'] = pr_auc\n",
    "            torch.save(classifier.state_dict(), 'best_classifier.pth')\n",
    "\n",
    "    # Cargar el mejor clasificador\n",
    "    classifier.load_state_dict(torch.load('best_classifier.pth'))\n",
    "    classifier.eval()\n",
    "\n",
    "    # ============================\n",
    "    # Evaluar el Clasificador en el Conjunto de Test\n",
    "    # ============================\n",
    "    print(\"Evaluando en test Same/Different con el mejor clasificador...\")\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x1_batch, x2_batch, sd_label in tqdm(test_sd_dataloader, desc=\"Evaluando en test\"):\n",
    "            x1_batch, x2_batch, sd_label = x1_batch.to(device), x2_batch.to(device), sd_label.to(device)\n",
    "            z1 = f_theta(x1_batch)\n",
    "            z2 = f_theta(x2_batch)\n",
    "            z_pred = iwm_predictor(z1, generate_action_params(x1_batch, x2_batch))\n",
    "            z1 = get_latent(z1)\n",
    "            z2 = get_latent(z2)\n",
    "            z_pred_minus_z2 = z_pred - z2\n",
    "            features = torch.cat([z1, z2, z_pred_minus_z2], dim=1)  # [batch_size, 3 * latent_dim]\n",
    "            logits = classifier(features)\n",
    "            probs = torch.softmax(logits, dim=1)[:,1]  # Probabilidad de la clase 'DIFFERENT'\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_trues.append(sd_label.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_trues = np.concatenate(all_trues)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    f1 = f1_score(all_trues, all_preds, average='weighted')\n",
    "    prec = precision_score(all_trues, all_preds, average='weighted')\n",
    "    rec = recall_score(all_trues, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "    roc_auc = roc_auc_score(all_trues, all_probs)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(all_trues, all_probs)\n",
    "    pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(\"Same/Different Test Metrics (mejor clasificador):\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "    print(f\"PR-AUC: {pr_auc}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Graficar Curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(all_trues, all_probs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "    plt.title('Curva ROC - Clasificador Same/Different')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Graficar Curva Precision-Recall\n",
    "    plt.figure()\n",
    "    plt.plot(recall_vals, precision_vals, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Curva Precision-Recall - Clasificador Same/Different')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Curvas ROC y Precision-Recall guardadas como 'roc_curve.png' y 'precision_recall_curve.png' respectivamente.\")\n",
    "    print(\"Proceso final completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
